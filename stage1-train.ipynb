{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/torchlibrosa/torchlibrosa-0.0.5-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:11:08.638092Z","iopub.execute_input":"2023-04-20T19:11:08.638956Z","iopub.status.idle":"2023-04-20T19:11:21.241180Z","shell.execute_reply.started":"2023-04-20T19:11:08.638906Z","shell.execute_reply":"2023-04-20T19:11:21.239043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q torchtoolbox timm","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:11:21.244944Z","iopub.execute_input":"2023-04-20T19:11:21.246124Z","iopub.status.idle":"2023-04-20T19:11:34.324498Z","shell.execute_reply.started":"2023-04-20T19:11:21.246047Z","shell.execute_reply":"2023-04-20T19:11:34.322154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install catalyst==20.12","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:11:34.327713Z","iopub.execute_input":"2023-04-20T19:11:34.328393Z","iopub.status.idle":"2023-04-20T19:11:47.186161Z","shell.execute_reply.started":"2023-04-20T19:11:34.328322Z","shell.execute_reply":"2023-04-20T19:11:47.184336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/timm-pytorch-image-models/pytorch-image-models-master/","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"# import glob\nimport os\nimport random\nimport warnings\nfrom functools import partial\n\n# import colorednoise as cn\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport scipy as sp\nimport soundfile as sf\nimport timm\nimport torch\nimport torch.optim as optim\nfrom pytorch_lightning import LightningDataModule, callbacks\n\n# from pytorch_lightning.utilities import rank_zero_info\nfrom sklearn import model_selection\nfrom sklearn.metrics import f1_score\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchaudio.transforms import AmplitudeToDB, MelSpectrogram","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport audioread\nimport logging\nimport os\nimport random\nimport time\nimport warnings\n\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport soundfile as sf\nimport timm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as torchdata\n\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom albumentations.core.transforms_interface import ImageOnlyTransform\n# from torchlibrosa.stft import LogmelFilterBank, Spectrogram\n# from torchlibrosa.augmentation import SpecAugmentation\nfrom tqdm import tqdm","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"def set_seed(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)  # type: ignore\n    torch.backends.cudnn.deterministic = True  # type: ignore\n    torch.backends.cudnn.benchmark = True  # type: ignore\n    \n    \ndef get_logger(out_file=None):\n    logger = logging.getLogger()\n    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n    logger.handlers = []\n    logger.setLevel(logging.INFO)\n\n    handler = logging.StreamHandler()\n    handler.setFormatter(formatter)\n    handler.setLevel(logging.INFO)\n    logger.addHandler(handler)\n\n    if out_file is not None:\n        fh = logging.FileHandler(out_file)\n        fh.setFormatter(formatter)\n        fh.setLevel(logging.INFO)\n        logger.addHandler(fh)\n    logger.info(\"logger set up\")\n    return logger\n    \n    \n@contextmanager\ndef timer(name: str, logger: Optional[logging.Logger] = None):\n    t0 = time.time()\n    msg = f\"[{name}] start\"\n    if logger is None:\n        print(msg)\n    else:\n        logger.info(msg)\n    yield\n\n    msg = f\"[{name}] done in {time.time() - t0:.2f} s\"\n    if logger is None:\n        print(msg)\n    else:\n        logger.info(msg)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger = get_logger(\"main.log\")\nset_seed(1213)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_ROOT = Path(\"/kaggle/input/birdclef-2023\")\nTRAIN_AUDIO_ROOT = Path(\"/kaggle/input/birdclef-2023/train_audio\")\nTRAIN_AUDIO_IMAGES_SAVE_ROOT = Path(\"audio_images\") # Where to save the mels images\nTRAIN_AUDIO_IMAGES_SAVE_ROOT.mkdir(exist_ok=True, parents=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:11:47.231353Z","iopub.execute_input":"2023-04-20T19:11:47.232778Z","iopub.status.idle":"2023-04-20T19:11:47.246596Z","shell.execute_reply.started":"2023-04-20T19:11:47.232692Z","shell.execute_reply":"2023-04-20T19:11:47.244719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    ######################\n    # Globals #\n    ######################\n    seed = 1213\n    epochs = 32\n    train = True\n    folds = [4]\n    img_size = 224\n    main_metric = \"epoch_f1_at_05\"\n    minimize_metric = False\n\n    ######################\n    # Data #\n    ######################\n    DATA_ROOT = Path(\"/kaggle/input/birdclef-2023\")\n    TRAIN_AUDIO_ROOT = Path(\"/kaggle/input/birdclef-2023/train_audio\")\n    TRAIN_AUDIO_IMAGES_SAVE_ROOT = Path(\"audio_images\") # Where to save the mels images\n    TRAIN_AUDIO_IMAGES_SAVE_ROOT.mkdir(exist_ok=True, parents=True)\n\n    ######################\n    # Dataset #\n    ######################\n    transforms = {\n        \"train\": [{\"name\": \"Normalize\"}],\n        \"valid\": [{\"name\": \"Normalize\"}],\n        \"test\": [{\"name\": \"Normalize\"}]\n    }\n    period = 15\n#     period = 5\n    n_mels = 224\n    fmin = 20\n    fmax = 16000\n    n_fft = 2048\n    hop_length = 512\n    sample_rate = 32000\n    \n    melspectrogram_parameters = {\n        \"n_mels\": 224,\n        \"fmin\": 20,\n        \"fmax\": 16000\n    }\n\n    sample_rate = 32000\n    target_columns = [\n        'abethr1', 'abhori1', 'abythr1', 'afbfly1', 'afdfly1', 'afecuc1',\n        'affeag1', 'afgfly1', 'afghor1', 'afmdov1', 'afpfly1', 'afpkin1',\n        'afpwag1', 'afrgos1', 'afrgrp1', 'afrjac1', 'afrthr1', 'amesun2',\n        'augbuz1', 'bagwea1', 'barswa', 'bawhor2', 'bawman1', 'bcbeat1',\n        'beasun2', 'bkctch1', 'bkfruw1', 'blacra1', 'blacuc1', 'blakit1',\n        'blaplo1', 'blbpuf2', 'blcapa2', 'blfbus1', 'blhgon1', 'blhher1',\n        'blksaw1', 'blnmou1', 'blnwea1', 'bltapa1', 'bltbar1', 'bltori1',\n        'blwlap1', 'brcale1', 'brcsta1', 'brctch1', 'brcwea1', 'brican1',\n        'brobab1', 'broman1', 'brosun1', 'brrwhe3', 'brtcha1', 'brubru1',\n        'brwwar1', 'bswdov1', 'btweye2', 'bubwar2', 'butapa1', 'cabgre1',\n        'carcha1', 'carwoo1', 'categr', 'ccbeat1', 'chespa1', 'chewea1',\n        'chibat1', 'chtapa3', 'chucis1', 'cibwar1', 'cohmar1', 'colsun2',\n        'combul2', 'combuz1', 'comsan', 'crefra2', 'crheag1', 'crohor1',\n        'darbar1', 'darter3', 'didcuc1', 'dotbar1', 'dutdov1', 'easmog1',\n        'eaywag1', 'edcsun3', 'egygoo', 'equaka1', 'eswdov1', 'eubeat1',\n        'fatrav1', 'fatwid1', 'fislov1', 'fotdro5', 'gabgos2', 'gargan',\n        'gbesta1', 'gnbcam2', 'gnhsun1', 'gobbun1', 'gobsta5', 'gobwea1',\n        'golher1', 'grbcam1', 'grccra1', 'grecor', 'greegr', 'grewoo2',\n        'grwpyt1', 'gryapa1', 'grywrw1', 'gybfis1', 'gycwar3', 'gyhbus1',\n        'gyhkin1', 'gyhneg1', 'gyhspa1', 'gytbar1', 'hadibi1', 'hamerk1',\n        'hartur1', 'helgui', 'hipbab1', 'hoopoe', 'huncis1', 'hunsun2',\n        'joygre1', 'kerspa2', 'klacuc1', 'kvbsun1', 'laudov1', 'lawgol',\n        'lesmaw1', 'lessts1', 'libeat1', 'litegr', 'litswi1', 'litwea1',\n        'loceag1', 'lotcor1', 'lotlap1', 'luebus1', 'mabeat1', 'macshr1',\n        'malkin1', 'marsto1', 'marsun2', 'mcptit1', 'meypar1', 'moccha1',\n        'mouwag1', 'ndcsun2', 'nobfly1', 'norbro1', 'norcro1', 'norfis1',\n        'norpuf1', 'nubwoo1', 'pabspa1', 'palfly2', 'palpri1', 'piecro1',\n        'piekin1', 'pitwhy', 'purgre2', 'pygbat1', 'quailf1', 'ratcis1',\n        'raybar1', 'rbsrob1', 'rebfir2', 'rebhor1', 'reboxp1', 'reccor',\n        'reccuc1', 'reedov1', 'refbar2', 'refcro1', 'reftin1', 'refwar2',\n        'rehblu1', 'rehwea1', 'reisee2', 'rerswa1', 'rewsta1', 'rindov',\n        'rocmar2', 'rostur1', 'ruegls1', 'rufcha2', 'sacibi2', 'sccsun2',\n        'scrcha1', 'scthon1', 'shesta1', 'sichor1', 'sincis1', 'slbgre1',\n        'slcbou1', 'sltnig1', 'sobfly1', 'somgre1', 'somtit4', 'soucit1',\n        'soufis1', 'spemou2', 'spepig1', 'spewea1', 'spfbar1', 'spfwea1',\n        'spmthr1', 'spwlap1', 'squher1', 'strher', 'strsee1', 'stusta1',\n        'subbus1', 'supsta1', 'tacsun1', 'tafpri1', 'tamdov1', 'thrnig1',\n        'trobou1', 'varsun2', 'vibsta2', 'vilwea1', 'vimwea1', 'walsta1',\n        'wbgbir1', 'wbrcha2', 'wbswea1', 'wfbeat1', 'whbcan1', 'whbcou1',\n        'whbcro2', 'whbtit5', 'whbwea1', 'whbwhe3', 'whcpri2', 'whctur2',\n        'wheslf1', 'whhsaw1', 'whihel1', 'whrshr1', 'witswa1', 'wlwwar',\n        'wookin1', 'woosan', 'wtbeat1', 'yebapa1', 'yebbar1', 'yebduc1',\n        'yebere1', 'yebgre1', 'yebsto1', 'yeccan1', 'yefcan', 'yelbis1',\n        'yenspu1', 'yertin1', 'yesbar1', 'yespet1', 'yetgre1', 'yewgre1']\n    \n  \n    ######################\n    # Loaders #\n    ######################\n    loader_params = {\n        \"train\": {\n            \"batch_size\": 32,\n            \"num_workers\": 20,\n            \"shuffle\": True\n        },\n        \"valid\": {\n            \"batch_size\": 32,\n            \"num_workers\": 20,\n            \"shuffle\": False\n        },\n        \"test\": {\n            \"batch_size\": 64,\n            \"num_workers\": 20,\n            \"shuffle\": False\n        }\n    }\n\n\n    ######################\n    # Split #\n    ######################\n    split = \"StratifiedKFold\"\n    split_params = {\n        \"n_splits\": 5,\n        \"shuffle\": True,\n        \"random_state\": 1213\n    }\n\n    ######################\n    # Model #\n    ######################\n    base_model_name = \"tf_efficientnet_b0_ns\"\n    pooling = \"max\"\n    pretrained = True\n    num_classes = 264\n    in_channels = 1\n\n    ######################\n    # Criterion #\n    ######################\n    loss_name = \"BCEFocal2WayLoss\"\n    loss_params: dict = {}\n\n    ######################\n    # Optimizer #\n    ######################\n    optimizer_name = \"Adam\"\n    base_optimizer = \"Adam\"\n    optimizer_params = {\n        \"lr\": 0.001\n    }\n    # For SAM optimizer\n    base_optimizer = \"Adam\"\n\n    ######################\n    # Scheduler #\n    ######################\n    scheduler_name = \"CosineAnnealingLR\"\n    scheduler_params = {\n        \"T_max\": 10\n    }\n ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport datetime\nimport time\n# import glob\nimport os\nimport random\nimport warnings\nfrom contextlib import contextmanager\n# from copy import deepcopy\nfrom functools import partial\nfrom typing import Optional, List\nimport logging\nfrom pathlib import Path\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport scipy as sp\nimport soundfile as sf\nimport timm\nimport torch\nimport torch.optim as optim\nfrom pytorch_lightning import LightningDataModule, callbacks\nfrom tqdm.notebook import tqdm\nimport joblib, json\n# from pytorch_lightning.utilities import rank_zero_info\nimport sklearn.metrics\nfrom sklearn.metrics import f1_score, average_precision_score\nfrom  soundfile import SoundFile\nfrom  sklearn.model_selection  import StratifiedKFold\n\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchaudio.transforms import AmplitudeToDB, MelSpectrogram\n\nwarnings.simplefilter(\"ignore\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:11:47.191582Z","iopub.execute_input":"2023-04-20T19:11:47.193231Z","iopub.status.idle":"2023-04-20T19:11:47.207543Z","shell.execute_reply.started":"2023-04-20T19:11:47.193139Z","shell.execute_reply":"2023-04-20T19:11:47.205958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SR = 32000\nSEED = 666","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:11:47.209328Z","iopub.execute_input":"2023-04-20T19:11:47.209769Z","iopub.status.idle":"2023-04-20T19:11:47.229294Z","shell.execute_reply.started":"2023-04-20T19:11:47.209728Z","shell.execute_reply":"2023-04-20T19:11:47.227638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_ROOT = Path(\"/kaggle/input/birdclef-2023\")\nTRAIN_AUDIO_ROOT = Path(\"/kaggle/input/birdclef-2023/train_audio\")\nTRAIN_AUDIO_IMAGES_SAVE_ROOT = Path(\"audio_images\") # Where to save the mels images\nTRAIN_AUDIO_IMAGES_SAVE_ROOT.mkdir(exist_ok=True, parents=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:11:47.231353Z","iopub.execute_input":"2023-04-20T19:11:47.232778Z","iopub.status.idle":"2023-04-20T19:11:47.246596Z","shell.execute_reply.started":"2023-04-20T19:11:47.232692Z","shell.execute_reply":"2023-04-20T19:11:47.244719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"train = pd.read_csv('/kaggle/input/birdclef-2023/train_metadata.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T12:55:25.601726Z","iopub.execute_input":"2023-04-20T12:55:25.602278Z","iopub.status.idle":"2023-04-20T12:55:25.712775Z","shell.execute_reply.started":"2023-04-20T12:55:25.602225Z","shell.execute_reply":"2023-04-20T12:55:25.709586Z"}}},{"cell_type":"code","source":"def get_audio_info(filepath):\n    \"\"\"Get some properties from  an audio file\"\"\"\n    with SoundFile(filepath) as f:\n        sr = f.samplerate\n        frames = f.frames\n        duration = float(frames)/sr\n    return {\"frames\": frames, \"sr\": sr, \"duration\": duration}","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:11:47.249152Z","iopub.execute_input":"2023-04-20T19:11:47.250018Z","iopub.status.idle":"2023-04-20T19:11:47.266607Z","shell.execute_reply.started":"2023-04-20T19:11:47.249946Z","shell.execute_reply":"2023-04-20T19:11:47.265019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef make_df(n_splits=4, seed=SEED, nrows=None):\n    \n    df = pd.read_csv(DATA_ROOT/\"train_metadata.csv\", nrows=nrows)\n\n    LABEL_IDS = {label: label_id for label_id,label in enumerate(sorted(df[\"primary_label\"].unique()))}\n\n    df[\"filepath\"] = [str(TRAIN_AUDIO_ROOT/filename) for primary_label,filename in zip(df.primary_label, df.filename) ]\n\n    pool = joblib.Parallel(4)\n    mapper = joblib.delayed(get_audio_info)\n    tasks = [mapper(filepath) for filepath in df.filepath]\n\n    df = pd.concat([df, pd.DataFrame(pool(tqdm(tasks)))], axis=1, sort=False)\n    \n    skf = StratifiedKFold(n_splits=n_splits, random_state=seed, shuffle=True)\n    splits = skf.split(np.arange(len(df)), y=df.primary_label.values)\n    df[\"fold\"] = -1\n\n    for fold, (train_set, val_set) in enumerate(splits):\n        \n        df.loc[df.index[val_set], \"fold\"] = fold\n\n    return LABEL_IDS, df","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:11:47.268727Z","iopub.execute_input":"2023-04-20T19:11:47.269171Z","iopub.status.idle":"2023-04-20T19:11:47.284029Z","shell.execute_reply.started":"2023-04-20T19:11:47.269128Z","shell.execute_reply":"2023-04-20T19:11:47.282396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LABEL_IDS, df = make_df(nrows=None)\n\ndf.to_csv(\"rich_train_metadata.csv\", index=True)\nwith open(\"LABEL_IDS.json\", \"w\") as f:\n    json.dump(LABEL_IDS, f)\n\nprint(df.shape)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:11:47.285851Z","iopub.execute_input":"2023-04-20T19:11:47.286708Z","iopub.status.idle":"2023-04-20T19:12:08.413015Z","shell.execute_reply.started":"2023-04-20T19:11:47.286654Z","shell.execute_reply":"2023-04-20T19:12:08.411125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"fold\"].value_counts()\ndf.to_csv(\"train_metadata_new.csv\")\ntrain_df = df\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:12:08.417686Z","iopub.execute_input":"2023-04-20T19:12:08.418198Z","iopub.status.idle":"2023-04-20T19:12:08.662975Z","shell.execute_reply.started":"2023-04-20T19:12:08.418156Z","shell.execute_reply":"2023-04-20T19:12:08.661044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_name = sorted(os.listdir('/kaggle/input/birdclef-2023/train_audio'))","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:12:08.664806Z","iopub.execute_input":"2023-04-20T19:12:08.665722Z","iopub.status.idle":"2023-04-20T19:12:08.675339Z","shell.execute_reply.started":"2023-04-20T19:12:08.665662Z","shell.execute_reply":"2023-04-20T19:12:08.672399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(class_name)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:12:08.678716Z","iopub.execute_input":"2023-04-20T19:12:08.679209Z","iopub.status.idle":"2023-04-20T19:12:08.695167Z","shell.execute_reply.started":"2023-04-20T19:12:08.679168Z","shell.execute_reply":"2023-04-20T19:12:08.693675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_columns = ['abethr1',\n 'abhori1',\n 'abythr1',\n 'afbfly1',\n 'afdfly1',\n 'afecuc1',\n 'affeag1',\n 'afgfly1',\n 'afghor1',\n 'afmdov1',\n 'afpfly1',\n 'afpkin1',\n 'afpwag1',\n 'afrgos1',\n 'afrgrp1',\n 'afrjac1',\n 'afrthr1',\n 'amesun2',\n 'augbuz1',\n 'bagwea1',\n 'barswa',\n 'bawhor2',\n 'bawman1',\n 'bcbeat1',\n 'beasun2',\n 'bkctch1',\n 'bkfruw1',\n 'blacra1',\n 'blacuc1',\n 'blakit1',\n 'blaplo1',\n 'blbpuf2',\n 'blcapa2',\n 'blfbus1',\n 'blhgon1',\n 'blhher1',\n 'blksaw1',\n 'blnmou1',\n 'blnwea1',\n 'bltapa1',\n 'bltbar1',\n 'bltori1',\n 'blwlap1',\n 'brcale1',\n 'brcsta1',\n 'brctch1',\n 'brcwea1',\n 'brican1',\n 'brobab1',\n 'broman1',\n 'brosun1',\n 'brrwhe3',\n 'brtcha1',\n 'brubru1',\n 'brwwar1',\n 'bswdov1',\n 'btweye2',\n 'bubwar2',\n 'butapa1',\n 'cabgre1',\n 'carcha1',\n 'carwoo1',\n 'categr',\n 'ccbeat1',\n 'chespa1',\n 'chewea1',\n 'chibat1',\n 'chtapa3',\n 'chucis1',\n 'cibwar1',\n 'cohmar1',\n 'colsun2',\n 'combul2',\n 'combuz1',\n 'comsan',\n 'crefra2',\n 'crheag1',\n 'crohor1',\n 'darbar1',\n 'darter3',\n 'didcuc1',\n 'dotbar1',\n 'dutdov1',\n 'easmog1',\n 'eaywag1',\n 'edcsun3',\n 'egygoo',\n 'equaka1',\n 'eswdov1',\n 'eubeat1',\n 'fatrav1',\n 'fatwid1',\n 'fislov1',\n 'fotdro5',\n 'gabgos2',\n 'gargan',\n 'gbesta1',\n 'gnbcam2',\n 'gnhsun1',\n 'gobbun1',\n 'gobsta5',\n 'gobwea1',\n 'golher1',\n 'grbcam1',\n 'grccra1',\n 'grecor',\n 'greegr',\n 'grewoo2',\n 'grwpyt1',\n 'gryapa1',\n 'grywrw1',\n 'gybfis1',\n 'gycwar3',\n 'gyhbus1',\n 'gyhkin1',\n 'gyhneg1',\n 'gyhspa1',\n 'gytbar1',\n 'hadibi1',\n 'hamerk1',\n 'hartur1',\n 'helgui',\n 'hipbab1',\n 'hoopoe',\n 'huncis1',\n 'hunsun2',\n 'joygre1',\n 'kerspa2',\n 'klacuc1',\n 'kvbsun1',\n 'laudov1',\n 'lawgol',\n 'lesmaw1',\n 'lessts1',\n 'libeat1',\n 'litegr',\n 'litswi1',\n 'litwea1',\n 'loceag1',\n 'lotcor1',\n 'lotlap1',\n 'luebus1',\n 'mabeat1',\n 'macshr1',\n 'malkin1',\n 'marsto1',\n 'marsun2',\n 'mcptit1',\n 'meypar1',\n 'moccha1',\n 'mouwag1',\n 'ndcsun2',\n 'nobfly1',\n 'norbro1',\n 'norcro1',\n 'norfis1',\n 'norpuf1',\n 'nubwoo1',\n 'pabspa1',\n 'palfly2',\n 'palpri1',\n 'piecro1',\n 'piekin1',\n 'pitwhy',\n 'purgre2',\n 'pygbat1',\n 'quailf1',\n 'ratcis1',\n 'raybar1',\n 'rbsrob1',\n 'rebfir2',\n 'rebhor1',\n 'reboxp1',\n 'reccor',\n 'reccuc1',\n 'reedov1',\n 'refbar2',\n 'refcro1',\n 'reftin1',\n 'refwar2',\n 'rehblu1',\n 'rehwea1',\n 'reisee2',\n 'rerswa1',\n 'rewsta1',\n 'rindov',\n 'rocmar2',\n 'rostur1',\n 'ruegls1',\n 'rufcha2',\n 'sacibi2',\n 'sccsun2',\n 'scrcha1',\n 'scthon1',\n 'shesta1',\n 'sichor1',\n 'sincis1',\n 'slbgre1',\n 'slcbou1',\n 'sltnig1',\n 'sobfly1',\n 'somgre1',\n 'somtit4',\n 'soucit1',\n 'soufis1',\n 'spemou2',\n 'spepig1',\n 'spewea1',\n 'spfbar1',\n 'spfwea1',\n 'spmthr1',\n 'spwlap1',\n 'squher1',\n 'strher',\n 'strsee1',\n 'stusta1',\n 'subbus1',\n 'supsta1',\n 'tacsun1',\n 'tafpri1',\n 'tamdov1',\n 'thrnig1',\n 'trobou1',\n 'varsun2',\n 'vibsta2',\n 'vilwea1',\n 'vimwea1',\n 'walsta1',\n 'wbgbir1',\n 'wbrcha2',\n 'wbswea1',\n 'wfbeat1',\n 'whbcan1',\n 'whbcou1',\n 'whbcro2',\n 'whbtit5',\n 'whbwea1',\n 'whbwhe3',\n 'whcpri2',\n 'whctur2',\n 'wheslf1',\n 'whhsaw1',\n 'whihel1',\n 'whrshr1',\n 'witswa1',\n 'wlwwar',\n 'wookin1',\n 'woosan',\n 'wtbeat1',\n 'yebapa1',\n 'yebbar1',\n 'yebduc1',\n 'yebere1',\n 'yebgre1',\n 'yebsto1',\n 'yeccan1',\n 'yefcan',\n 'yelbis1',\n 'yenspu1',\n 'yertin1',\n 'yesbar1',\n 'yespet1',\n 'yetgre1',\n 'yewgre1']","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:12:08.697173Z","iopub.execute_input":"2023-04-20T19:12:08.697757Z","iopub.status.idle":"2023-04-20T19:12:08.721602Z","shell.execute_reply.started":"2023-04-20T19:12:08.697710Z","shell.execute_reply":"2023-04-20T19:12:08.720011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bird2id = {b: i for i, b in enumerate(target_columns)}\nid2bird = {i: b for i, b in enumerate(target_columns)}","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:12:08.723599Z","iopub.execute_input":"2023-04-20T19:12:08.724831Z","iopub.status.idle":"2023-04-20T19:12:08.742539Z","shell.execute_reply.started":"2023-04-20T19:12:08.724618Z","shell.execute_reply":"2023-04-20T19:12:08.740627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Compose:\n    def __init__(self, transforms: list):\n        self.transforms = transforms\n\n    def __call__(self, y: np.ndarray, sr):\n        for trns in self.transforms:\n            y = trns(y, sr)\n        return y\n\n\nclass AudioTransform:\n    def __init__(self, always_apply=False, p=0.5):\n        self.always_apply = always_apply\n        self.p = p\n\n    def __call__(self, y: np.ndarray, sr):\n        if self.always_apply:\n            return self.apply(y, sr=sr)\n        else:\n            if np.random.rand() < self.p:\n                return self.apply(y, sr=sr)\n            else:\n                return y\n\n    def apply(self, y: np.ndarray, **params):\n        raise NotImplementedError\n\n\nclass OneOf(Compose):\n    # https://github.com/albumentations-team/albumentations/blob/master/albumentations/core/composition.py\n    def __init__(self, transforms, p=0.5):\n        super().__init__(transforms)\n        self.p = p\n        transforms_ps = [t.p for t in transforms]\n        s = sum(transforms_ps)\n        self.transforms_ps = [t / s for t in transforms_ps]\n\n    def __call__(self, y: np.ndarray, sr):\n        data = y\n        if self.transforms_ps and (random.random() < self.p):\n            random_state = np.random.RandomState(random.randint(0, 2 ** 32 - 1))\n            t = random_state.choice(self.transforms, p=self.transforms_ps)\n            data = t(y, sr)\n        return data\n\n\nclass Normalize(AudioTransform):\n    def __init__(self, always_apply=False, p=1):\n        super().__init__(always_apply, p)\n\n    def apply(self, y: np.ndarray, **params):\n        max_vol = np.abs(y).max()\n        y_vol = y * 1 / max_vol\n        return np.asfortranarray(y_vol)\n\n\nclass NewNormalize(AudioTransform):\n    def __init__(self, always_apply=False, p=1):\n        super().__init__(always_apply, p)\n\n    def apply(self, y: np.ndarray, **params):\n        y_mm = y - y.mean()\n        return y_mm / y_mm.abs().max()\n\n\nclass NoiseInjection(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, max_noise_level=0.5):\n        super().__init__(always_apply, p)\n\n        self.noise_level = (0.0, max_noise_level)\n\n    def apply(self, y: np.ndarray, **params):\n        noise_level = np.random.uniform(*self.noise_level)\n        noise = np.random.randn(len(y))\n        augmented = (y + noise * noise_level).astype(y.dtype)\n        return augmented\n\n\nclass GaussianNoise(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20):\n        super().__init__(always_apply, p)\n\n        self.min_snr = min_snr\n        self.max_snr = max_snr\n\n    def apply(self, y: np.ndarray, **params):\n        snr = np.random.uniform(self.min_snr, self.max_snr)\n        a_signal = np.sqrt(y ** 2).max()\n        a_noise = a_signal / (10 ** (snr / 20))\n\n        white_noise = np.random.randn(len(y))\n        a_white = np.sqrt(white_noise ** 2).max()\n        augmented = (y + white_noise * 1 / a_white * a_noise).astype(y.dtype)\n        return augmented\n\n\nclass PinkNoise(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20):\n        super().__init__(always_apply, p)\n\n        self.min_snr = min_snr\n        self.max_snr = max_snr\n\n    def apply(self, y: np.ndarray, **params):\n        snr = np.random.uniform(self.min_snr, self.max_snr)\n        a_signal = np.sqrt(y ** 2).max()\n        a_noise = a_signal / (10 ** (snr / 20))\n\n        pink_noise = cn.powerlaw_psd_gaussian(1, len(y))\n        a_pink = np.sqrt(pink_noise ** 2).max()\n        augmented = (y + pink_noise * 1 / a_pink * a_noise).astype(y.dtype)\n        return augmented\n\n\nclass PitchShift(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, max_range=5):\n        super().__init__(always_apply, p)\n        self.max_range = max_range\n\n    def apply(self, y: np.ndarray, sr, **params):\n        n_steps = np.random.randint(-self.max_range, self.max_range)\n        augmented = librosa.effects.pitch_shift(y, sr, n_steps)\n        return augmented\n\n\nclass TimeStretch(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, max_rate=1):\n        super().__init__(always_apply, p)\n        self.max_rate = max_rate\n\n    def apply(self, y: np.ndarray, **params):\n        rate = np.random.uniform(0, self.max_rate)\n        augmented = librosa.effects.time_stretch(y, rate)\n        return augmented\n\n\ndef _db2float(db: float, amplitude=True):\n    if amplitude:\n        return 10 ** (db / 20)\n    else:\n        return 10 ** (db / 10)\n\n\ndef volume_down(y: np.ndarray, db: float):\n    \"\"\"\n    Low level API for decreasing the volume\n    Parameters\n    ----------\n    y: numpy.ndarray\n        stereo / monaural input audio\n    db: float\n        how much decibel to decrease\n    Returns\n    -------\n    applied: numpy.ndarray\n        audio with decreased volume\n    \"\"\"\n    applied = y * _db2float(-db)\n    return applied\n\n\ndef volume_up(y: np.ndarray, db: float):\n    \"\"\"\n    Low level API for increasing the volume\n    Parameters\n    ----------\n    y: numpy.ndarray\n        stereo / monaural input audio\n    db: float\n        how much decibel to increase\n    Returns\n    -------\n    applied: numpy.ndarray\n        audio with increased volume\n    \"\"\"\n    applied = y * _db2float(db)\n    return applied\n\n\nclass RandomVolume(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, limit=10):\n        super().__init__(always_apply, p)\n        self.limit = limit\n\n    def apply(self, y: np.ndarray, **params):\n        db = np.random.uniform(-self.limit, self.limit)\n        if db >= 0:\n            return volume_up(y, db)\n        else:\n            return volume_down(y, db)\n\n\nclass CosineVolume(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, limit=10):\n        super().__init__(always_apply, p)\n        self.limit = limit\n\n    def apply(self, y: np.ndarray, **params):\n        db = np.random.uniform(-self.limit, self.limit)\n        cosine = np.cos(np.arange(len(y)) / len(y) * np.pi * 2)\n        dbs = _db2float(cosine * db)\n        return y * dbs\n\n\ndef drop_stripes(image: np.ndarray, dim: int, drop_width: int, stripes_num: int):\n    total_width = image.shape[dim]\n    lowest_value = image.min()\n    for _ in range(stripes_num):\n        distance = np.random.randint(low=0, high=drop_width, size=(1,))[0]\n        begin = np.random.randint(low=0, high=total_width - distance, size=(1,))[0]\n\n        if dim == 0:\n            image[begin : begin + distance] = lowest_value\n        elif dim == 1:\n            image[:, begin + distance] = lowest_value\n        elif dim == 2:\n            image[:, :, begin + distance] = lowest_value\n    return image\n\ndef load_wave_and_crop(filename, period, start=None):\n    waveform_orig, sample_rate = sf.read(filename)\n    wave_len = len(waveform_orig)\n    waveform = np.concatenate([waveform_orig, waveform_orig, waveform_orig])\n    while len(waveform) < (period * sample_rate * 3):\n        waveform = np.concatenate([waveform, waveform_orig])\n    if start is not None:\n        start = start - (period - 5) / 2 * sample_rate\n        while start < 0:\n            start += wave_len\n        start = int(start)\n        # start = int(start * sample_rate) + wave_len\n    else:\n        start = np.random.randint(wave_len)\n    waveform_seg = waveform[start : start + int(period * sample_rate)]\n    return waveform_orig, waveform_seg, sample_rate, start\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:12:08.745652Z","iopub.execute_input":"2023-04-20T19:12:08.746253Z","iopub.status.idle":"2023-04-20T19:12:08.800790Z","shell.execute_reply.started":"2023-04-20T19:12:08.746193Z","shell.execute_reply":"2023-04-20T19:12:08.799319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BirdClef2023Dataset(Dataset):\n    def __init__(\n        self,\n        data_path: str = \"/kaggle/input/birdclef-2023/train_audio\",\n        period: float = 15.0,\n        secondary_coef: float = 1.0,\n        smooth_label: float = 0.0,\n        df: pd.DataFrame = train_df,\n        train: bool = True,\n    ):\n\n        self.df = df\n        self.data_path = data_path\n        self.filenames = df[\"filename\"]\n        self.primary_label = df[\"primary_label\"]\n\n        self.secondary_labels = (\n            df[\"secondary_labels\"]\n            .map(\n                lambda s: s.replace(\"[\", \"\")\n                .replace(\"]\", \"\")\n                .replace(\",\", \"\")\n                .replace(\"'\", \"\")\n                .split(\" \")\n            )\n            .values\n        )\n        self.secondary_coef = secondary_coef\n        self.type = df[\"type\"]\n        self.period = period\n        self.smooth_label = smooth_label + 1e-6\n        if train:\n            self.wave_transforms = Compose(\n                [\n                    OneOf(\n                        [\n                            NoiseInjection(p=1, max_noise_level=0.04),\n                            GaussianNoise(p=1, min_snr=5, max_snr=20),\n                            PinkNoise(p=1, min_snr=5, max_snr=20),\n                        ],\n                        p=0.2,\n                    ),\n                    RandomVolume(p=0.2, limit=4),\n                    Normalize(p=1),\n                ]\n            )\n        else:\n            self.wave_transforms = Compose(\n                [\n                    Normalize(p=1),\n                ]\n            )\n        self.train = train\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        filename = os.path.join(\n            self.data_path, self.primary_label[idx], self.filenames[idx]\n        )\n        if self.train:\n            waveform, waveform_seg, sample_rate, start = load_wave_and_crop(\n                filename, self.period\n            )\n        else:\n            waveform, waveform_seg, sample_rate, start = load_wave_and_crop(\n                filename, self.period, 0\n            )\n\n        waveform_seg = self.wave_transforms(waveform_seg, sr=sample_rate)\n\n        waveform_seg = torch.Tensor(np.nan_to_num(waveform_seg))\n\n        target = np.zeros(264, dtype=np.float32)\n        primary_label = bird2id[self.primary_label[idx]]\n        target[primary_label] = 1.0\n\n        for s in self.secondary_labels[idx]:\n            if s == \"rocpig1\":\n                s = \"rocpig\"\n            if s != \"\" and s in bird2id.keys():\n                target[bird2id[s]] = self.secondary_coef\n\n        target = torch.Tensor(target)\n        return {\n            \"wave\": waveform_seg,\n            \"target\": (target > 0.01).float(),\n            \"loss_target\": target * (1 - self.smooth_label)\n            + self.smooth_label / target.size(-1),\n        }\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:12:08.803248Z","iopub.execute_input":"2023-04-20T19:12:08.803886Z","iopub.status.idle":"2023-04-20T19:12:08.825623Z","shell.execute_reply.started":"2023-04-20T19:12:08.803811Z","shell.execute_reply":"2023-04-20T19:12:08.824091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BirdClef2023DataModule(LightningDataModule):\n    def __init__(\n        self,\n        num_workers: int = 0,\n        batch_size: int = 32,\n        period: float = 15.0,\n        secondary_coef: float = 1.0,\n        train_df: pd.DataFrame = train_df,\n        valid_df: pd.DataFrame = train_df,\n        ):\n        super().__init__()\n\n        self._num_workers = num_workers\n        self._batch_size = batch_size\n        self.period = period\n        self.secondary_coef = secondary_coef\n        self.train_df = train_df\n        self.valid_df = valid_df\n\n    def create_dataset(self, train=True):\n        return (\n            BirdClef2023Dataset(\n                period=self.period,\n                secondary_coef=self.secondary_coef,\n                train=True,\n                df=self.train_df,\n            )\n            if train\n            else BirdClef2023Dataset(\n                period=self.period,\n                secondary_coef=self.secondary_coef,\n                train=False,\n                df=self.valid_df,\n            )\n        )\n\n    def __dataloader(self, train: bool):\n        \"\"\"Train/validation loaders.\"\"\"\n        dataset = self.create_dataset(train)\n        return DataLoader(\n            dataset=dataset,\n            batch_size=self._batch_size,\n            num_workers=self._num_workers,\n            shuffle=train,\n            drop_last=train,\n            worker_init_fn=lambda x: np.random.seed(np.random.get_state()[1][0] + x),\n        )\n\n    def train_dataloader(self):\n        return self.__dataloader(train=True)\n\n    def val_dataloader(self):\n        return self.__dataloader(train=False)\n\n    @staticmethod\n    def add_model_specific_args(parent_parser):\n        parser = parent_parser.add_argument_group(\"BirdClef2021DataModule\")\n        parser.add_argument(\n            \"--num_workers\",\n            default=0,\n            type=int,\n            metavar=\"W\",\n            help=\"number of CPU workers\",\n            dest=\"num_workers\",\n        )\n        parser.add_argument(\n            \"--batch_size\",\n            default=32,\n            type=int,\n            metavar=\"BS\",\n            help=\"number of sample in a batch\",\n            dest=\"batch_size\",\n        )\n        parser.add_argument(\n            \"--period\",\n            default=15.0,\n            type=float,\n            metavar=\"P\",\n            help=\"period for training\",\n            dest=\"period\",\n        )\n        parser.add_argument(\n            \"--secondary_coef\",\n            default=1.0,\n            type=float,\n            metavar=\"SC\",\n            help=\"secondary coef\",\n            dest=\"secondary_coef\",\n        )\n        return parent_parser\n    \n    \nclass AdaptiveConcatPool2d(nn.Module):\n    def __init__(self, sz=None):\n        super().__init__()\n        sz = sz or (1, 1)\n        self.ap = nn.AdaptiveAvgPool2d(sz)\n        self.mp = nn.AdaptiveMaxPool2d(sz)\n\n    def forward(self, x):\n        return torch.cat([self.mp(x), self.ap(x)], 1)\n\n\nclass Flatten(nn.Module):\n    \"\"\"\n    Simple class for flattening layer.\n    \"\"\"\n\n    def forward(self, x):\n        return x.view(x.size()[0], -1)\n\n\ndef gem(x, p=3, eps=1e-6):\n    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n\n\nclass GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM, self).__init__()\n        self.p = torch.nn.Parameter(torch.ones(1) * p)\n        self.eps = eps\n\n    def forward(self, x):\n        return gem(x, p=self.p, eps=self.eps)\n\n\ndef gem_freq(x, p=3, eps=1e-6):\n    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), 1)).pow(1.0 / p)\n\n\nclass GeMFreq(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super().__init__()\n        self.p = torch.nn.Parameter(torch.ones(1) * p)\n        self.eps = eps\n\n    def forward(self, x):\n        return gem_freq(x, p=self.p, eps=self.eps)\n\n\nclass NormalizeMelSpec(nn.Module):\n    def __init__(self, eps=1e-6):\n        super().__init__()\n        self.eps = eps\n\n    def forward(self, X):\n        mean = X.mean((1, 2), keepdim=True)\n        std = X.std((1, 2), keepdim=True)\n        Xstd = (X - mean) / (std + self.eps)\n        norm_min, norm_max = Xstd.min(-1)[0].min(-1)[0], Xstd.max(-1)[0].max(-1)[0]\n        fix_ind = (norm_max - norm_min) > self.eps * torch.ones_like(\n            (norm_max - norm_min)\n        )\n        V = torch.zeros_like(Xstd)\n        if fix_ind.sum():\n            V_fix = Xstd[fix_ind]\n            norm_max_fix = norm_max[fix_ind, None, None]\n            norm_min_fix = norm_min[fix_ind, None, None]\n            V_fix = torch.max(\n                torch.min(V_fix, norm_max_fix),\n                norm_min_fix,\n            )\n            # print(V_fix.shape, norm_min_fix.shape, norm_max_fix.shape)\n            V_fix = (V_fix - norm_min_fix) / (norm_max_fix - norm_min_fix)\n            V[fix_ind] = V_fix\n        return V\n\n\nclass AttHead(nn.Module):\n    def __init__(\n        self, in_chans, p=0.5, num_class=264, train_period=15.0, infer_period=5.0\n    ):\n        super().__init__()\n        self.train_period = train_period\n        self.infer_period = infer_period\n        self.pooling = GeMFreq()\n\n        self.dense_layers = nn.Sequential(\n            nn.Dropout(p / 2),\n            nn.Linear(in_chans, 512),\n            nn.ReLU(),\n            nn.Dropout(p),\n        )\n        self.attention = nn.Conv1d(\n            in_channels=512,\n            out_channels=num_class,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=True,\n        )\n        self.fix_scale = nn.Conv1d(\n            in_channels=512,\n            out_channels=num_class,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=True,\n        )\n\n    def forward(self, feat):\n        feat = self.pooling(feat).squeeze(-2).permute(0, 2, 1)  # (bs, time, ch)\n\n        feat = self.dense_layers(feat).permute(0, 2, 1)  # (bs, 512, time)\n        time_att = torch.tanh(self.attention(feat))\n        assert self.train_period >= self.infer_period\n        if self.training or self.train_period == self.infer_period:\n\n            clipwise_pred = torch.sum(\n                torch.sigmoid(self.fix_scale(feat)) * torch.softmax(time_att, dim=-1),\n                dim=-1,\n            )  # sum((bs, 24, time), -1) -> (bs, 24)\n            logits = torch.sum(\n                self.fix_scale(feat) * torch.softmax(time_att, dim=-1),\n                dim=-1,\n            )\n        else:\n            feat_time = feat.size(-1)\n            start = (\n                feat_time / 2 - feat_time * (self.infer_period / self.train_period) / 2\n            )\n            end = start + feat_time * (self.infer_period / self.train_period)\n            start = int(start)\n            end = int(end)\n            feat = feat[:, :, start:end]\n            att = torch.softmax(time_att[:, :, start:end], dim=-1)\n            clipwise_pred = torch.sum(\n                torch.sigmoid(self.fix_scale(feat)) * att,\n                dim=-1,\n            )\n            logits = torch.sum(\n                self.fix_scale(feat) * att,\n                dim=-1,\n            )\n            time_att = time_att[:, :, start:end]\n        return (\n            logits,\n            clipwise_pred,\n            self.fix_scale(feat).permute(0, 2, 1),\n            time_att.permute(0, 2, 1),\n        )\n\n\nclass AttModel(nn.Module):\n    def __init__(\n        self,\n        backbone=\"EfficientNetB1\",\n        p=0.5,\n        n_mels=224,\n        num_class=264,\n        train_period=15.0,\n        infer_period=5.0,\n        in_chans=1,\n    ):\n        super().__init__()\n        self.n_mels = n_mels\n        self.logmelspec_extractor = nn.Sequential(\n            MelSpectrogram(\n                32000,\n                n_mels=n_mels,\n                f_min=20,\n                n_fft=2048,\n                hop_length=512,\n                normalized=True,\n            ),\n            AmplitudeToDB(top_db=80.0),\n            NormalizeMelSpec(),\n        )\n        self.backbone = timm.create_model(\n            backbone, features_only=True, pretrained=True, in_chans=in_chans\n        )\n        encoder_channels = self.backbone.feature_info.channels()\n        dense_input = encoder_channels[-1]\n        self.head = AttHead(\n            dense_input,\n            p=p,\n            num_class=num_class,\n            train_period=train_period,\n            infer_period=infer_period,\n        )\n\n    def forward(self, input):\n        feats = self.backbone(input)\n        return self.head(feats[-1])\n\n\ndef row_wise_f1_score_micro(y_true, y_pred, threshold=0.5):\n    def event_thresholder(x, threshold):\n        return x > threshold\n\n    return f1_score(\n        y_true=y_true, y_pred=event_thresholder(y_pred, threshold), average=\"samples\"\n    )\n\n\ndef padded_cmap(solution, submission, padding_factor=5):\n    solution = solution#.drop(['row_id'], axis=1, errors='ignore')\n    submission = submission#.drop(['row_id'], axis=1, errors='ignore')\n    new_rows = []\n    for i in range(padding_factor):\n        new_rows.append([1 for i in range(len(solution.columns))])\n    new_rows = pd.DataFrame(new_rows)\n    new_rows.columns = solution.columns\n    padded_solution = pd.concat([solution, new_rows]).reset_index(drop=True).copy()\n    padded_submission = pd.concat([submission, new_rows]).reset_index(drop=True).copy()\n    score = sklearn.metrics.average_precision_score(\n        padded_solution.values,\n        padded_submission.values,\n        average='macro',\n    )\n    return score\n\ndef map_score(solution, submission):\n    solution = solution#.drop(['row_id'], axis=1, errors='ignore')\n    submission = submission#.drop(['row_id'], axis=1, errors='ignore')\n    score = sklearn.metrics.average_precision_score(\n        solution.values,\n        submission.values,\n        average='micro',\n    )\n    return score\n\nclass ThresholdOptimizer:\n    def __init__(self, loss_fn):\n        self.coef_ = {}\n        self.loss_fn = loss_fn\n        self.coef_[\"x\"] = [0.5]\n\n    def _loss(self, coef, X, y):\n        ll = self.loss_fn(y, X, coef)\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._loss, X=X, y=y)\n        initial_coef = [0.5]\n        self.coef_ = sp.optimize.minimize(\n            loss_partial, initial_coef, method=\"nelder-mead\"\n        )\n\n    def coefficients(self):\n        return self.coef_[\"x\"]\n\n    def calc_score(self, X, y, coef):\n        return self.loss_fn(y, X, coef)\n\n\nclass Mixup(object):\n    def __init__(self, p=0.5, alpha=5):\n        self.p = p\n        self.alpha = alpha\n        self.lam = 1.0\n        self.do_mixup = False\n\n    def init_lambda(self):\n        if np.random.rand() < self.p:\n            self.do_mixup = True\n        else:\n            self.do_mixup = False\n        if self.do_mixup and self.alpha > 0.0:\n            self.lam = np.random.beta(self.alpha, self.alpha)\n        else:\n            self.lam = 1.0","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:14:57.044802Z","iopub.execute_input":"2023-04-20T19:14:57.046394Z","iopub.status.idle":"2023-04-20T19:14:57.108612Z","shell.execute_reply.started":"2023-04-20T19:14:57.046329Z","shell.execute_reply":"2023-04-20T19:14:57.107006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BirdClef2023Model(pl.LightningModule):\n    def __init__(\n        self,\n        backbone: str = \"EfficientNetB1\",\n        n_mels: int = 224,\n        batch_size: int = 32,\n        lr: float = 1e-3,\n        backbone_lr: float = None,\n        num_workers: int = 6,\n        period=15.0,\n        infer_period=15.0,\n        mixup_p=0.0,\n        mixup_alpha=0.5,\n        **kwargs,\n    ) -> None:\n        super().__init__()\n        self.backbone = backbone\n        self.n_mels = n_mels\n        # self.milestones = milestones\n        if self.batch_size==None:\n            self.batch_size = batch_size\n        self.lr = lr\n        self.backbone_lr = backbone_lr if backbone_lr is not None else lr\n        self.num_workers = num_workers\n        self.period = period\n        self.infer_period = infer_period\n        self.thresholder = ThresholdOptimizer(row_wise_f1_score_micro)\n        self.mixupper = Mixup(p=mixup_p, alpha=mixup_alpha)\n\n        self.decay = 0.99\n\n        self.__build_model()\n        self.save_hyperparameters()\n\n    def __build_model(self):\n        \"\"\"Define model layers & loss.\"\"\"\n\n        self.model = AttModel(\n            self.backbone,\n            p=0.5,\n            n_mels=self.n_mels,\n            num_class=264,\n            train_period=self.period,\n            infer_period=self.infer_period,\n        )\n        self.criterions = {\n            \"classification_clip\": nn.BCEWithLogitsLoss(),\n            \"classification_frame\": nn.BCEWithLogitsLoss(),\n        }\n\n    def forward(self, image):\n        \"\"\"Forward pass. Returns logits.\"\"\"\n        outputs = {}\n        (\n            outputs[\"logits\"],\n            outputs[\"output_clip\"],\n            outputs[\"output_frame\"],\n            outputs[\"output_attention\"],\n        ) = self.model(image)\n        return outputs\n\n    def loss(self, outputs, batch):\n        losses = {}\n        losses[\"loss_clip\"] = self.criterions[\"classification_clip\"](\n            torch.logit(outputs[\"output_clip\"]), batch[\"loss_target\"]\n        )\n        losses[\"loss_frame\"] = self.criterions[\"classification_frame\"](\n            outputs[\"output_frame\"].max(1)[0], batch[\"loss_target\"]\n        )\n        losses[\"loss\"] = losses[\"loss_clip\"] + losses[\"loss_frame\"] * 0.5\n        return losses\n\n    def training_step(self, batch, batch_idx):\n        self.mixupper.init_lambda()\n        step_output = {}\n        image = self.model.logmelspec_extractor(batch[\"wave\"])[:, None]\n        image = self.mixupper.lam * image + (1 - self.mixupper.lam) * image.flip(0)\n        outputs = self.forward(image)\n        batch[\"loss_target\"] = self.mixupper.lam * batch[\"loss_target\"] + (\n            1 - self.mixupper.lam\n        ) * batch[\"loss_target\"].flip(0)\n        batch[\"target\"] = self.mixupper.lam * batch[\"target\"] + (\n            1 - self.mixupper.lam\n        ) * batch[\"target\"].flip(0)\n\n        train_loss = self.loss(outputs, batch)\n\n        step_output.update(train_loss)\n        step_output.update({\"output_clip\": outputs[\"output_clip\"]})\n        step_output[\"target\"] = batch[\"target\"]\n        self.log_dict(\n            dict(\n                train_loss=train_loss[\"loss\"],\n                train_loss_frame=train_loss[\"loss_frame\"],\n                train_loss_clip=train_loss[\"loss_clip\"],\n            )\n        )\n        return step_output\n\n    def training_epoch_end(self, training_step_outputs):\n        y_true = []\n        y_pred = []\n        for tso in training_step_outputs:\n            y_true.append(tso[\"target\"])\n            y_pred.append(tso[\"output_clip\"])\n        y_true = torch.cat(y_true).cpu().numpy().astype(\"int\")\n        y_pred = torch.cat(y_pred).cpu().detach().numpy()\n        self.thresholder.fit(y_pred, y_true)\n        coef = self.thresholder.coefficients()\n\n        # print(output_val.shape)\n        val_df = pd.DataFrame(y_true, columns = birds)\n        pred_df = pd.DataFrame(y_pred, columns = birds)\n        \n        avg_score = padded_cmap(val_df, pred_df, padding_factor = 5)\n        avg_score2 = padded_cmap(val_df, pred_df, padding_factor = 3)\n        avg_score3 = sklearn.metrics.label_ranking_average_precision_score(y_true,y_pred)\n        \n        f1_score = self.thresholder.calc_score(y_pred, y_true, coef)\n        f1_score_05 = self.thresholder.calc_score(y_pred, y_true, [0.5])\n        f1_score_03 = self.thresholder.calc_score(y_pred, y_true, [0.3])\n        self.log_dict(\n            dict(\n                train_coef=coef,\n                train_avg_score=avg_score,\n                train_avg_score2=avg_score2,\n                train_avg_score3=avg_score3,\n            )\n        )\n\n    def validation_step(self, batch, batch_idx):\n        step_output = {}\n        image = self.model.logmelspec_extractor(batch[\"wave\"])[:, None]\n        outputs = self.forward(image)\n        valid_loss = self.loss(outputs, batch)\n        step_output.update({\"output_clip\": outputs[\"output_clip\"]})\n        step_output[\"target\"] = batch[\"target\"]\n        avg_loss = torch.stack([x['valid_loss'] for x in outputs]).mean()\n        self.log_dict(\n            dict(\n                val_loss=valid_loss[\"loss\"],\n                val_loss_frame=valid_loss[\"loss_frame\"],\n                val_loss_clip=valid_loss[\"loss_clip\"],\n            )\n        )\n        return step_output\n\n    def validation_epoch_end(self, validation_step_outputs):\n        y_pred = []\n        y_true = []\n        for vso in validation_step_outputs:\n            y_true.append(vso[\"target\"])\n            y_pred.append(vso[\"output_clip\"])\n        y_true = torch.cat(y_true).cpu().numpy().astype(\"int\")\n        y_pred = torch.cat(y_pred).cpu().detach().numpy()\n        self.thresholder.fit(y_pred, y_true)\n        coef = self.thresholder.coefficients()\n        \n        val_df = pd.DataFrame(y_true, columns = birds)\n        pred_df = pd.DataFrame(y_pred, columns = birds)\n        \n        avg_score = padded_cmap(val_df, pred_df, padding_factor = 5)\n        avg_score2 = padded_cmap(val_df, pred_df, padding_factor = 3)\n        avg_score3 = sklearn.metrics.label_ranking_average_precision_score(y_true,y_pred)\n        \n        f1_score = self.thresholder.calc_score(y_pred, y_true, coef)\n        f1_score_05 = self.thresholder.calc_score(y_pred, y_true, [0.5])\n        f1_score_03 = self.thresholder.calc_score(y_pred, y_true, [0.3])\n        self.log_dict(\n            dict(\n                val_coef=coef,\n                val_avg_score=avg_score,\n                val_avg_score2=avg_score2,\n                val_avg_score3=avg_score3,\n            )\n        )\n#         competition_metrics(output_val,target_val)\n        print(f'epoch {self.current_epoch} validation loss {avg_loss}')\n        print(f'epoch {self.current_epoch} validation C-MAP score pad 5 {avg_score}')\n        print(f'epoch {self.current_epoch} validation C-MAP score pad 3 {avg_score2}')\n        print(f'epoch {self.current_epoch} validation AP score {avg_score3}')\n    def optimizer_step(self, *args, **kwargs):\n        super().optimizer_step(*args, **kwargs)\n\n    def configure_optimizers(self):\n\n        optimizer = optim.Adam(\n            [\n                {\"params\": self.model.head.parameters(), \"lr\": self.lr},\n                {\"params\": self.model.backbone.parameters(), \"lr\": self.backbone_lr},\n            ],\n            lr=self.lr,\n            weight_decay=0.0001,\n        )\n        scheduler = CosineAnnealingLR(\n            optimizer,\n            T_max=self.trainer.max_epochs,\n            eta_min=1.0e-6,\n        )\n        return [optimizer], [scheduler]\n\n    @staticmethod\n    def add_model_specific_args(parent_parser):\n        parser = parent_parser.add_argument_group(\"TransferLearningModel\")\n        parser.add_argument(\n            \"--backbone\",\n            default=\"EfficientNetB1\",\n            type=str,\n            metavar=\"BK\",\n            help=\"Name (as in ``timm``) of the feature extractor\",\n        )\n        parser.add_argument(\n            \"--n_mels\", default=224, type=int, metavar=\"NM\", help=\"nmels\", dest=\"n_mels\"\n        )\n        parser.add_argument(\n            \"--epochs\", default=10, type=int, metavar=\"N\", help=\"total number of epochs\"\n        )\n        parser.add_argument(\n            \"--batch_size\",\n            default=32,\n            type=int,\n            metavar=\"B\",\n            help=\"batch size\",\n            dest=\"batch_size\",\n        )\n        parser.add_argument(\"--gpus\", type=int, default=0, help=\"number of gpus to use\")\n        parser.add_argument(\n            \"--lr\",\n            default=1e-3,\n            type=float,\n            metavar=\"LR\",\n            help=\"initial learning rate\",\n            dest=\"lr\",\n        )\n        parser.add_argument(\n            \"--backbone_lr\",\n            default=None,\n            type=float,\n            metavar=\"LR\",\n            help=\"initial learning rate for backbone network\",\n            dest=\"backbone_lr\",\n        )\n        parser.add_argument(\n            \"--mixup_p\",\n            default=0,\n            type=float,\n            metavar=\"MP\",\n            help=\"mixup proba\",\n            dest=\"mixup_p\",\n        )\n        parser.add_argument(\n            \"--mixup_alpha\",\n            default=0.8,\n            type=float,\n            metavar=\"ML\",\n            help=\"mixup alpha\",\n            dest=\"mixup_alpha\",\n        )\n        parser.add_argument(\n            \"--period\",\n            default=15.0,\n            type=float,\n            metavar=\"P\",\n            help=\"period for training\",\n            dest=\"period\",\n        )\n        parser.add_argument(\n            \"--infer_period\",\n            default=15.0,\n            type=float,\n            metavar=\"P\",\n            help=\"period for inference\",\n            dest=\"infer_period\",\n        )\n        return parent_parser\n\n\ndef get_args() -> argparse.Namespace:\n    parent_parser = argparse.ArgumentParser(add_help=False)\n    parent_parser.add_argument(\n        \"--seed\",\n        default=2023,\n        type=int,\n        metavar=\"SE\",\n        help=\"seed number\",\n        dest=\"seed\",\n    )\n    parent_parser.add_argument(\n        \"--debug\",\n        action=\"store_true\",\n        help=\"1 batch run for debug\",\n        dest=\"debug\",\n    )\n    dt_now = datetime.datetime.now()\n    parent_parser.add_argument(\n        \"--logdir\",\n        default=f\"{dt_now.strftime('%Y%m%d-%H-%M-%S')}\",\n    )\n    parent_parser.add_argument(\n        \"--fold\",\n        type=int,\n        default=0,\n    )\n\n    parser = BirdClef2023Model.add_model_specific_args(parent_parser)\n    parser = BirdClef2023DataModule.add_argparse_args(parser)\n\n    return parser.parse_args()\n\n\ndef main(args):\n    pl.seed_everything(args.seed)\n    assert args.fold < 4\n    for i in range(4):\n        if args.fold != i:\n            continue\n        train_df_fold = train_df[train_df.fold != i].reset_index(drop=True)\n        valid_df_fold = train_df[train_df.fold == i].reset_index(drop=True)\n        datamodule = BirdClef2023DataModule(\n            batch_size=args.batch_size,\n            num_workers=args.num_workers,\n            period=args.period,\n            secondary_coef=args.secondary_coef,\n            train_df=train_df_fold,\n            valid_df=valid_df_fold,\n        )\n        model = BirdClef2023Model(**vars(args))\n        rootdir = f\"/kaggle/logs/stage1/{args.logdir}/fold{i}\"\n        print(f\"logdir = {rootdir}\")\n        lr_monitor = callbacks.LearningRateMonitor()\n        loss_checkpoint = callbacks.ModelCheckpoint(\n            filename=\"best_loss\",\n            monitor=\"val_loss\",\n            save_top_k=1,\n            mode=\"min\",\n        )\n\n        f1_checkpoint = callbacks.ModelCheckpoint(\n            filename=\"best_f1\",\n            monitor=\"val_f1_score\",\n            save_top_k=1,\n            mode=\"max\",\n        )\n        Cmap_checkpoint = callbacks.ModelCheckpoint(\n            filename=\"best_Cmap\",\n            monitor=\"val_avg_score\",\n            save_top_k=1,\n            mode=\"max\",\n        )\n\n        trainer = pl.Trainer(\n            default_root_dir=rootdir,\n            progress_bar_refresh_rate=1,\n            sync_batchnorm=True,\n            # precision=16,\n            gpus=args.gpus,\n            max_epochs=args.epochs,\n            callbacks=[\n                loss_checkpoint,\n                f1_checkpoint,\n                lr_monitor,\n            ],\n            accelerator=\"ddp\",\n            fast_dev_run=args.debug,\n            num_sanity_val_steps=0,\n        )\n\n        trainer.fit(model, datamodule=datamodule)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:18:41.841724Z","iopub.execute_input":"2023-04-20T19:18:41.842336Z","iopub.status.idle":"2023-04-20T19:18:41.907828Z","shell.execute_reply.started":"2023-04-20T19:18:41.842289Z","shell.execute_reply":"2023-04-20T19:18:41.905578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main(get_args())","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:18:46.506253Z","iopub.execute_input":"2023-04-20T19:18:46.506840Z","iopub.status.idle":"2023-04-20T19:18:46.519309Z","shell.execute_reply.started":"2023-04-20T19:18:46.506781Z","shell.execute_reply":"2023-04-20T19:18:46.517498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}